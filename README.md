# Ollama

Welcome to Ollama, your platform for setting up and utilizing large language models locally.

## Quickstart

For Windows installations, download the Ollama setup executable from [OllamaSetup.exe](https://ollama.com/download/OllamaSetup.exe).

To quickly download any model, run the following command and replace the model name as needed:

```bash
ollama run llama2


# For example:

ollama run gemma:2b





